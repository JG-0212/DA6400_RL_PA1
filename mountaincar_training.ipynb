{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f43fd-9fe6-44e0-9a70-3b90a2c329be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scripts.agents import QLearningAgent, SARSAAgent\n",
    "from scripts.training import Trainer, trainingInspector\n",
    "from scripts.tilecoding import QTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f0af8-ff5d-4240-a546-e508f12387ab",
   "metadata": {},
   "source": [
    "### Top 3 hyperparameters for Q-Learning and SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c533b-641f-44ae-84e3-5c57e3e0a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 3 hyperparameters for Q-Learning and SARSA\n",
    "qlearning_hyperparameter_list = [\n",
    "    \n",
    "    # Best performing hyperparameters\n",
    "    {\n",
    "        \"num_episodes\": 10000,\n",
    "        \"max_return\": -100,\n",
    "        \"num_tiles_per_feature\": 20,\n",
    "        \"num_tilings\": 1,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"tau_start\": 100000,\n",
    "        \"tau_end\": 0.1,\n",
    "        \"decay_type\": \"exponential\",\n",
    "        \"frac_episodes_to_decay\": 0.1\n",
    "    }\n",
    "    # Second best performing hyperparameters\n",
    "    # {\n",
    "    #     \"num_episodes\": 10000,\n",
    "    #     \"max_return\": -100,\n",
    "    #     \"num_tiles_per_feature\": 20,\n",
    "    #     \"num_tilings\": 1,\n",
    "    #     \"learning_rate\": 0.1,\n",
    "    #     \"tau_start\": 100000,\n",
    "    #     \"tau_end\": 0.1,\n",
    "    #     \"decay_type\": \"exponential\",\n",
    "    #     \"frac_episodes_to_decay\": 0.1\n",
    "    # }\n",
    "    # Third best performing hyperparameters\n",
    "    # {\n",
    "    #     \"num_episodes\": 10000,\n",
    "    #     \"max_return\": -100,\n",
    "    #     \"num_tiles_per_feature\": 20,\n",
    "    #     \"num_tilings\": 1,\n",
    "    #     \"learning_rate\": 0.1,\n",
    "    #     \"tau_start\": 100000,\n",
    "    #     \"tau_end\": 0.1,\n",
    "    #     \"decay_type\": \"exponential\",\n",
    "    #     \"frac_episodes_to_decay\": 0.1\n",
    "    # }\n",
    "    \n",
    "]\n",
    "\n",
    "sarsa_hyperparameter_list = [\n",
    "    \n",
    "    # Best performing hyperparameters\n",
    "    {\n",
    "        \"num_episodes\": 10000,\n",
    "        \"max_return\": -100,\n",
    "        \"num_tiles_per_feature\": 20,\n",
    "        \"num_tilings\": 4,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"eps_start\": 1,\n",
    "        \"eps_end\": 0.01,\n",
    "        \"decay_type\": \"exponential\",\n",
    "        \"frac_episodes_to_decay\": 0.5\n",
    "    }\n",
    "    # Second best performing hyperparameters\n",
    "    # {\n",
    "    #     \"num_episodes\": 10000,\n",
    "    #     \"max_return\": -100,\n",
    "    #     \"num_tiles_per_feature\": 20,\n",
    "    #     \"num_tilings\": 4,\n",
    "    #     \"learning_rate\": 0.1,\n",
    "    #     \"eps_start\": 1,\n",
    "    #     \"eps_end\": 0.01,\n",
    "    #     \"decay_type\": \"exponential\",\n",
    "    #     \"frac_episodes_to_decay\": 0.5\n",
    "    # }\n",
    "    # Third best performing hyperparameters\n",
    "    # {\n",
    "    #     \"num_episodes\": 10000,\n",
    "    #     \"max_return\": -100,\n",
    "    #     \"num_tiles_per_feature\": 20,\n",
    "    #     \"num_tilings\": 4,\n",
    "    #     \"learning_rate\": 0.1,\n",
    "    #     \"eps_start\": 1,\n",
    "    #     \"eps_end\": 0.01,\n",
    "    #     \"decay_type\": \"exponential\",\n",
    "    #     \"frac_episodes_to_decay\": 0.5\n",
    "    # }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5c37b6-876d-4bdf-a5b7-79043c1c4ca2",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf95a7-91f2-4ee6-9402-8b8a0b148f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(arr, n=100):\n",
    "    csum = np.cumsum(arr)\n",
    "    csum[n:] = csum[n:] - csum[:-n]\n",
    "    return csum[n - 1:] / n\n",
    "\n",
    "def episode_trigger(x):\n",
    "    if x % 1000 == 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def compute_decay(param_start, param_end, frac_episodes_to_decay, num_episodes, decay_type):\n",
    "    if decay_type == 'linear':\n",
    "        param_decay = (param_start-param_end) / (frac_episodes_to_decay*num_episodes)\n",
    "    elif decay_type == 'exponential':\n",
    "        param_decay = 10 ** (np.log10(param_end/param_start) /\n",
    "                           (frac_episodes_to_decay*num_episodes))\n",
    "\n",
    "    return param_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca1663-ac37-40d5-94b8-541f12f6ea7b",
   "metadata": {},
   "source": [
    "## Code for testing and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cd7292-7e1b-4a68-83e7-fc00ba8faa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(env, agent, trainer, hyperparameter_list, num_experiments=5):\n",
    "    \"\"\"To test agents and compute metrics\n",
    "    \"\"\"\n",
    "\n",
    "    test_results = []\n",
    "\n",
    "    for test_num, test_hyperparameters in enumerate(hyperparameter_list):\n",
    "        \n",
    "        num_episodes = test_hyperparameters[\"num_episodes\"]    \n",
    "        max_return = test_hyperparameters[\"max_return\"]\n",
    "        num_tiles_per_feature = test_hyperparameters[\"num_tiles_per_feature\"]\n",
    "        num_tilings = test_hyperparameters[\"num_tilings\"]\n",
    "        learning_rate = test_hyperparameters[\"learning_rate\"]\n",
    "        decay_type = test_hyperparameters[\"decay_type\"]\n",
    "        frac_episodes_to_decay = test_hyperparameters[\"frac_episodes_to_decay\"]\n",
    "        \n",
    "        hyperparameters = {\n",
    "            \"NUM_TILES_PER_FEATURE\": [num_tiles_per_feature]*env.observation_space.shape[0],\n",
    "            \"NUM_TILINGS\": num_tilings,\n",
    "            \"GAMMA\": 0.99,\n",
    "            \"LR\": learning_rate,\n",
    "            \"decay_type\": decay_type,\n",
    "        }\n",
    "\n",
    "        if isinstance(agent, QLearningAgent):\n",
    "            label = \"Q-Learning\"\n",
    "            param_start = test_hyperparameters[\"tau_start\"]\n",
    "            param_end = test_hyperparameters[\"tau_end\"]\n",
    "            hyperparameters.update({\n",
    "                \"tau_start\": param_start,\n",
    "                \"tau_end\": param_end,\n",
    "                \"tau_decay\": compute_decay(param_start, param_end, \n",
    "                                           frac_episodes_to_decay, \n",
    "                                           num_episodes, decay_type)\n",
    "            })\n",
    "            \n",
    "        elif isinstance(agent, SARSAAgent):\n",
    "            label = \"SARSA\"\n",
    "            param_start = test_hyperparameters[\"eps_start\"]\n",
    "            param_end = test_hyperparameters[\"eps_end\"]\n",
    "            hyperparameters.update({\n",
    "                \"eps_start\": param_start,\n",
    "                \"eps_end\": param_end,\n",
    "                \"eps_decay\": compute_decay(param_start, param_end, \n",
    "                                           frac_episodes_to_decay, \n",
    "                                           num_episodes, decay_type)\n",
    "            })\n",
    "        \n",
    "        result_history = {\n",
    "            \"experiment\": [],\n",
    "            \"scores\": [],\n",
    "            \"moving_average_scores\": []\n",
    "        }\n",
    "        \n",
    "        for experiment in range(1, num_experiments+1):\n",
    "            agent.update_hyperparameters(**hyperparameters)\n",
    "        \n",
    "            ti = trainingInspector(max_return)\n",
    "            \n",
    "            results = trainer.training(\n",
    "                env, agent,\n",
    "                n_episodes=num_episodes,\n",
    "                process_training_info=ti.process_training_info)\n",
    "        \n",
    "            result_history[\"scores\"].append(results[\"scores\"])\n",
    "            result_history[\"moving_average_scores\"].append(moving_average(results[\"scores\"]))\n",
    "        \n",
    "        result_history[\"scores\"] = np.array(result_history[\"scores\"])\n",
    "        result_history[\"moving_average_scores\"] = np.array(result_history[\"moving_average_scores\"])\n",
    "        \n",
    "        metrics = {\n",
    "            \"label\": label + f\" hyperparams {test_num + 1}\",\n",
    "            \"episodes\": range(1, num_episodes+1),\n",
    "            \"rolling_episodes\": range(1, result_history[\"moving_average_scores\"].shape[1] + 1),\n",
    "            \"means\": result_history[\"scores\"].mean(axis=0),\n",
    "            \"std_dev\": result_history[\"scores\"].std(axis=0),\n",
    "            \"rolling_means\": result_history[\"moving_average_scores\"].mean(axis=0),\n",
    "            \"rolling_std_dev\": result_history[\"moving_average_scores\"].std(axis=0)\n",
    "        }\n",
    "\n",
    "        test_results.append(metrics)\n",
    "\n",
    "    return test_results\n",
    "\n",
    "def plot_test_results(test_results, experiments):\n",
    "\n",
    "    plt.subplots(1, 2, figsize=(16, 4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.grid()\n",
    "    plt.title(\"Scores vs Episodes\")\n",
    "    plt.xlabel(\"Episodes\")\n",
    "    plt.ylabel(\"Scores\")\n",
    "    for i in experiments:\n",
    "        label = test_results[i][\"label\"]\n",
    "        episodes = test_results[i][\"episodes\"]\n",
    "        means = test_results[i][\"means\"]\n",
    "        std_dev = test_results[i][\"std_dev\"]\n",
    "\n",
    "        plt.plot(episodes, means, linewidth = 0.2, label=label)\n",
    "        plt.fill_between(episodes, means-std_dev, means+std_dev, alpha=0.6)\n",
    "        \n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.grid()\n",
    "    plt.title(\"Rolling means of scores vs Episodes\")\n",
    "    plt.xlabel(\"Episodes\")\n",
    "    plt.ylabel(\"Rolling means of scores\")\n",
    "    for i in experiments:\n",
    "        label = test_results[i][\"label\"]\n",
    "        rolling_episodes = test_results[i][\"rolling_episodes\"]\n",
    "        rolling_means = test_results[i][\"rolling_means\"]\n",
    "        rolling_std_dev = test_results[i][\"rolling_std_dev\"]\n",
    "\n",
    "        plt.plot(rolling_episodes, rolling_means, linewidth = 1, label=label)\n",
    "        plt.fill_between(rolling_episodes, rolling_means-rolling_std_dev, rolling_means+rolling_std_dev, alpha=0.4)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447285fe-1a90-4bce-a7cd-eb0a06ffd0b6",
   "metadata": {},
   "source": [
    "## Running experiments - No Reward shaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2a030-617b-4470-9245-a44182a62460",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0', render_mode=\"rgb_array\")\n",
    "env = RecordVideo(\n",
    "    env,\n",
    "    video_folder=\"backups/mountaincar-qlearning-visualizations\",\n",
    "    name_prefix=\"eval\",\n",
    "    episode_trigger=episode_trigger\n",
    ")\n",
    "\n",
    "qlearning_agent = QLearningAgent(\n",
    "    state_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "sarsa_agent = SARSAAgent(\n",
    "    state_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "trainer = Trainer()\n",
    "qlearning_results = test_agent(env, qlearning_agent, trainer, qlearning_hyperparameter_list, num_experiments=5)\n",
    "sarsa_results = test_agent(env, sarsa_agent, trainer, sarsa_hyperparameter_list, num_experiments=5)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd30ebf-fd50-4d53-9a91-1ae25ae28943",
   "metadata": {},
   "source": [
    "## Reward Shaping experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95887d-d21d-417c-92c4-caba1d953e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewShaper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.prev_vel = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        observation, reward, terminated, truncated, info = self.env.step(action)\n",
    "        reward += 100*(action-1)*self.prev_vel\n",
    "        self.prev_vel = observation[1]\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "class MountainCarTrainer(Trainer):\n",
    "    def compute_score(self, reward):\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae5621-d7f4-4bd7-a24f-cc81af8c38ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0', render_mode=\"rgb_array\")\n",
    "env = RecordVideo(\n",
    "    env,\n",
    "    video_folder=\"backups/mountaincar-qlearning-visualizations\",\n",
    "    name_prefix=\"eval\",\n",
    "    episode_trigger=episode_trigger\n",
    ")\n",
    "env = RewShaper(env)\n",
    "\n",
    "qlearning_agent = QLearningAgent(\n",
    "    state_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "sarsa_agent = SARSAAgent(\n",
    "    state_space=env.observation_space,\n",
    "    action_space=env.action_space,\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "trainer = MountainCarTrainer()\n",
    "qlearning_results = test_agent(env, qlearning_agent, trainer, qlearning_hyperparameter_list, num_experiments=1)\n",
    "sarsa_results = test_agent(env, sarsa_agent, trainer, sarsa_hyperparameter_list, num_experiments=1)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66050cc-1480-4d82-9d6e-62ff01fa1208",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results = qlearning_results\n",
    "plot_test_results(combined_results, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c8fef1-c1d9-433f-a541-62b9082e4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = np.array(qlearning_agent.QTable)\n",
    "im = np.reshape(table, (20,20,3))\n",
    "im = (im-np.min(im))/(np.max(im)-np.min(im))\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749c9c4-3a0b-4936-ae6f-88f6f614eb66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "rl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
